# Hackerschool Medallion Architecture - Microsoft Fabric

Medallion Architecture implementation (Bronze â†’ Silver â†’ Gold) for Hackerschool data lakehouse on Microsoft Fabric.

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Architecture](#architecture)
- [Project Structure](#project-structure)
- [Getting Started](#getting-started)
- [Deployment](#deployment)
- [Configuration](#configuration)
- [Monitoring](#monitoring)
- [Development](#development)
- [Contributing](#contributing)

---

## ğŸ¯ Overview

This project implements a production-ready data lakehouse for Hackerschool using Microsoft Fabric's Medallion Architecture pattern. It processes data from Microsoft Dataverse through three quality layers:

- **Bronze**: Raw data (1:1 copy from Dataverse)
- **Silver**: Cleaned and validated data with quality checks
- **Gold**: Business-ready analytics with dimensional modeling and SCD Type 2

### Key Features

âœ… **Config-Driven Transformations** - Add new tables without code changes
âœ… **Data Quality Framework** - Automated validation with quarantine pattern
âœ… **SCD Type 2** - Historical tracking for dimension tables
âœ… **Comprehensive Monitoring** - Metrics, logging, and alerting
âœ… **Multi-Environment** - Dev, Test, Prod configurations
âœ… **Delta Lake** - ACID transactions and time travel

### MVP Scope (Week 1-2)

**Tables in Scope:**
- `contact` - Students, teachers, coaches (SCD Type 2)
- `account` - Partner organizations (SCD Type 2)
- `hs_course` - Course/session data

**Status:** ğŸš§ **In Development**
- âœ… SQL Schemas created
- âœ… Bronze â†’ Silver (contact) notebook
- âœ… Silver â†’ Gold SCD (contact) notebook
- âœ… Monitoring infrastructure
- â³ Account and Course notebooks (next)
- â³ Pipeline orchestration deployment
- â³ Power BI dashboards

---

## ğŸ—ï¸ Architecture

### Medallion Layers

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         DATAVERSE                               â”‚
â”‚                   (Microsoft Dynamics 365)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚ Fabric Link
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  BRONZE LAYER - Raw Data (hs_bronze_dev)                        â”‚
â”‚  â€¢ 1:1 copy from Dataverse                                      â”‚
â”‚  â€¢ No transformations                                           â”‚
â”‚  â€¢ Delta Lake format                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚ DQ Checks + Cleansing
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SILVER LAYER - Cleaned Data (hs_silver_dev)                    â”‚
â”‚  â€¢ Data quality validation                                      â”‚
â”‚  â€¢ Standardization (trim, lowercase)                            â”‚
â”‚  â€¢ Deduplication                                                â”‚
â”‚  â€¢ Invalid â†’ Quarantine                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚ SCD Type 2 + Aggregations
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  GOLD LAYER - Analytics Ready (hs_gold_dev)                     â”‚
â”‚  â€¢ Dimensional modeling (Star schema)                           â”‚
â”‚  â€¢ SCD Type 2 for history tracking                              â”‚
â”‚  â€¢ Business aggregations                                        â”‚
â”‚  â€¢ Power BI ready                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Quality & Monitoring

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MONITORING LAYER (hs_monitoring_dev)                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Pipeline Metrics â”‚  â”‚ Quarantine Records     â”‚   â”‚
â”‚  â”‚ â€¢ Records in/out â”‚  â”‚ â€¢ Invalid data         â”‚   â”‚
â”‚  â”‚ â€¢ Duration       â”‚  â”‚ â€¢ Error details        â”‚   â”‚
â”‚  â”‚ â€¢ Error rates    â”‚  â”‚ â€¢ Resolution tracking  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ DQ Rules         â”‚  â”‚ Pipeline Run History   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Project Structure

```
hckrschl-deploy/
â”œâ”€â”€ notebooks/                          # Spark notebooks for data processing
â”‚   â”œâ”€â”€ bronze_to_silver_contact.py    # âœ… Contact DQ pipeline
â”‚   â”œâ”€â”€ silver_to_gold_scd_contact.py  # âœ… Contact SCD Type 2
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ common.py                   # âœ… Shared utility functions
â”‚
â”œâ”€â”€ sql/                                # SQL scripts
â”‚   â”œâ”€â”€ schema/
â”‚   â”‚   â”œâ”€â”€ 01_monitoring_tables.sql   # âœ… Monitoring infrastructure
â”‚   â”‚   â””â”€â”€ 02_transformation_config.sql # âœ… Config-driven framework
â”‚   â””â”€â”€ seeds/
â”‚       â””â”€â”€ transformation_config_seed.sql # âœ… Initial config data
â”‚
â”œâ”€â”€ pipelines/                          # Fabric pipeline definitions
â”‚   â””â”€â”€ medallion_orchestrator.json    # âœ… Main orchestration pipeline
â”‚
â”œâ”€â”€ config/                             # Environment configurations
â”‚   â”œâ”€â”€ dev.json                        # âœ… Development settings
â”‚   â”œâ”€â”€ test.json                       # âœ… Test settings
â”‚   â””â”€â”€ prod.json                       # âœ… Production settings
â”‚
â”œâ”€â”€ context/                            # Planning & architecture docs
â”‚   â”œâ”€â”€ architecture-flow.md           # Detailed architecture guide
â”‚   â”œâ”€â”€ medallion-plan.md              # Technical specs
â”‚   â””â”€â”€ deployment-plan.md             # 2-week implementation plan
â”‚
â”œâ”€â”€ tests/                              # Unit and integration tests (TBD)
â”œâ”€â”€ .github/workflows/                  # CI/CD pipelines (TBD)
â””â”€â”€ README.md                           # This file
```

---

## ğŸš€ Getting Started

### Prerequisites

1. **Microsoft Fabric Workspace** with:
   - Lakehouse capability enabled
   - Notebook capability enabled
   - Pipeline capability enabled

2. **Microsoft Dataverse** environment:
   - Fabric Link configured
   - Tables: contact, account, hs_course

3. **Access & Permissions**:
   - Fabric Workspace Contributor or Admin
   - Dataverse System Administrator (for link setup)

### Quick Start (Dev Environment)

#### Step 1: Create Lakehouses

In Microsoft Fabric workspace `hs-fabric-dev`, create:

```
hs_bronze_dev      (use existing Dataverse link: hs_shareddev)
hs_silver_dev      (new)
hs_gold_dev        (new)
hs_monitoring_dev  (new)
```

#### Step 2: Setup Monitoring Tables

1. Open SQL endpoint for `hs_monitoring_dev`
2. Run: `sql/schema/01_monitoring_tables.sql`
3. Verify tables created:
   - `pipeline_metrics`
   - `quarantine_records`
   - `dq_rules`
   - `pipeline_run_history`

#### Step 3: Setup Transformation Config

1. Open SQL endpoint for `hs_silver_dev`
2. Run: `sql/schema/02_transformation_config.sql`
3. Run: `sql/seeds/transformation_config_seed.sql`
4. Verify config loaded:
   ```sql
   SELECT config_id, source_table, target_table, active
   FROM transformation_config
   WHERE active = TRUE;
   ```

#### Step 4: Upload Notebooks

1. Import notebooks from `notebooks/` to Fabric workspace:
   - `bronze_to_silver_contact.py`
   - `silver_to_gold_scd_contact.py`
   - `utils/common.py`

2. Attach to lakehouse: `hs_silver_dev` (default)

#### Step 5: Run First Pipeline

**Manual execution:**

```python
# In Fabric notebook or SQL endpoint
# 1. Run Bronze â†’ Silver
notebook: bronze_to_silver_contact
parameters: {"environment": "dev"}

# 2. Run Silver â†’ Gold
notebook: silver_to_gold_scd_contact
parameters: {"environment": "dev"}
```

**Check results:**

```sql
-- Silver data
SELECT COUNT(*) as record_count FROM hs_silver_dev.contact;

-- Gold data (current)
SELECT COUNT(*) as current_count
FROM hs_gold_dev.dim_contact_scd
WHERE is_current = TRUE;

-- Metrics
SELECT * FROM hs_monitoring_dev.pipeline_metrics
ORDER BY start_time DESC
LIMIT 5;

-- Quarantine
SELECT error_type, COUNT(*) as error_count
FROM hs_monitoring_dev.quarantine_records
GROUP BY error_type;
```

---

## ğŸ”§ Configuration

### Environment-Specific Settings

Configuration files in `config/` control behavior per environment:

| Setting | Dev | Test | Prod |
|---------|-----|------|------|
| Error Threshold | 10% | 5% | 2% |
| Batch Size | 1,000 | 5,000 | 10,000 |
| Schedule | 2:00 AM | 3:00 AM | 1:00 AM |
| Monitoring | INFO | INFO | WARN |

### Adding New Tables

**Option 1: Config-Driven (Recommended)**

Add entry to `transformation_config`:

```sql
INSERT INTO transformation_config VALUES (
    'mytable_bronze_silver_dq',
    'bronze.mytable',
    'silver.mytable',
    'silver',
    'dq_check',
    '{"validations": [...], "transformations": [...]}',
    10,
    true,
    1000,
    NULL,
    CURRENT_TIMESTAMP(),
    NULL,
    'data-team',
    'Description of mytable transformation'
);
```

**Option 2: Copy Existing Notebook**

1. Copy `bronze_to_silver_contact.py` â†’ `bronze_to_silver_mytable.py`
2. Update table names and validation rules
3. Add to pipeline orchestrator

---

## ğŸ“Š Monitoring

### Key Metrics

**Pipeline Metrics Table:**
```sql
SELECT
    stage,
    source_table,
    AVG(error_rate) as avg_error_rate,
    AVG(duration_sec) as avg_duration,
    SUM(records_written) as total_records
FROM hs_monitoring_dev.pipeline_metrics
WHERE start_time >= CURRENT_DATE() - INTERVAL 7 DAYS
GROUP BY stage, source_table;
```

**Quarantine Dashboard:**
```sql
SELECT
    source_table,
    error_type,
    COUNT(*) as error_count,
    MAX(created_at) as last_occurrence
FROM hs_monitoring_dev.quarantine_records
WHERE status = 'new'
GROUP BY source_table, error_type
ORDER BY error_count DESC;
```

### Alerts (To Be Configured)

Azure Monitor alerts trigger on:
- Error rate > threshold
- Pipeline failures
- Long-running pipelines (> 2 hours)
- Quarantine spike

---

## ğŸ‘©â€ğŸ’» Development

### Local Testing

**Prerequisites:**
- Python 3.10+
- PySpark 3.4+
- pytest

```bash
# Install dependencies
pip install -r requirements.txt  # TBD

# Run unit tests
pytest tests/  # TBD

# Run notebook locally (with Databricks Connect)
python notebooks/bronze_to_silver_contact.py  # TBD
```

### Branching Strategy

- `main` - Production code
- `develop` - Integration branch
- `feature/*` - Feature branches
- `hotfix/*` - Emergency fixes

### Code Quality

- **Linting**: `flake8` (Python), `sqlfluff` (SQL)
- **Formatting**: `black` (Python)
- **Type Hints**: Use for utility functions
- **Documentation**: Docstrings for all functions

---

## ğŸ“– Additional Documentation

See `context/` folder for detailed planning documents:

- **[architecture-flow.md](context/architecture-flow.md)** - Deep-dive into architecture decisions (899 lines)
- **[medallion-plan.md](context/medallion-plan.md)** - Executive summary and technical specs (301 lines)
- **[deployment-plan.md](deployment-plan.md)** - 14-day implementation roadmap (517 lines)

---

## ğŸ¤ Contributing

### Current Contributors

- Stefan Kochems (EY) - Architecture & Planning
- Saber - Implementation

### How to Contribute

1. Create feature branch: `git checkout -b feature/my-feature`
2. Make changes and test locally
3. Commit with clear messages
4. Push and create Pull Request
5. Tag reviewers: @stefan-kochems

---

## ğŸ“ License

Internal Hackerschool project - not for public distribution.

---

## ğŸ†˜ Support

**Issues:** Create GitHub issue with label:
- `bug` - Something isn't working
- `enhancement` - New feature request
- `question` - Need help

**Contact:**
- Data Team: data-team@hackerschool.de
- Stefan Kochems: stefan.kochems@ey.com

---

## ğŸ—ºï¸ Roadmap

### âœ… Phase 1: MVP (Weeks 1-2)
- [x] Architecture design
- [x] SQL schemas
- [x] Contact table pipeline
- [ ] Account table pipeline
- [ ] Course table pipeline
- [ ] Pipeline orchestration
- [ ] Power BI dashboards

### ğŸš§ Phase 2: Scale (Weeks 3-4)
- [ ] Config-driven generic notebooks
- [ ] All Dataverse tables onboarded
- [ ] CI/CD pipeline
- [ ] Test environment deployment
- [ ] Performance optimization

### ğŸ“… Phase 3: Production (Week 5+)
- [ ] Production deployment
- [ ] Monitoring & alerting
- [ ] Data lineage tracking
- [ ] User documentation
- [ ] Training sessions

---

**Last Updated:** 2025-10-26
**Version:** 0.1.0 (MVP in progress)
**Repository:** [github.com/hackerschool/fabric-medallion](https://github.com/hackerschool/fabric-medallion)
